{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e1a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace as dfc\n",
    "from deepface import DeepFace\n",
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0655aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare one image to another.\n",
    "\n",
    "verification = dfc.verify(img1_path = \"aa.jpg\", img2_path = \"he.jpg\", enforce_detection = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef299ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': False, 'distance': 0.4514450189855428, 'max_threshold_to_verify': 0.4, 'model': 'VGG-Face', 'similarity_metric': 'cosine'}\n"
     ]
    }
   ],
   "source": [
    "print(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ede58da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification['verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e6fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f645e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  facial_db  folder were previously stored in  representations_openface.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  12  representations found in  representations_openface.pkl\n",
      "find function lasts  2.291323661804199  seconds\n"
     ]
    }
   ],
   "source": [
    "# Compare one image to many\n",
    "# Find how many images in our database is of the same person\n",
    "\n",
    "recognition = dfc.find(img_path = \"aa.jpg\", db_path = 'facial_db', model_name= \"OpenFace\",distance_metric='euclidean_l2' , enforce_detection = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84224f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           identity  OpenFace_euclidean_l2\n",
      "0  facial_db/aa.jpg                    0.0\n"
     ]
    }
   ],
   "source": [
    "print(recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943d6b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognition.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a50f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 39, 'region': {'x': 629, 'y': 95, 'w': 438, 'h': 438}, 'gender': 'Man', 'emotion': {'angry': 0.0032818988984217867, 'disgust': 1.5824858784485585e-10, 'fear': 4.6278788090603484e-05, 'happy': 98.6477255821228, 'sad': 0.01688048942014575, 'surprise': 2.3841462848395167e-05, 'neutral': 1.3320459052920341}, 'dominant_emotion': 'happy', 'race': {'asian': 4.1030065629776846e-10, 'indian': 4.840239875569807e-08, 'black': 3.618810708993364e-11, 'white': 99.98990297317505, 'middle eastern': 0.008241998875746503, 'latino hispanic': 0.0018571601685835049}, 'dominant_race': 'white'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Facial Analysis\n",
    "\n",
    "analysis = DeepFace.analyze(img_path = \"aa.jpg\", actions = [\"age\", \"gender\", \"emotion\", \"race\"])\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755677e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector backend is  opencv\n",
      "Facenet  is built\n",
      "Emotion model loaded\n",
      "Age model loaded\n",
      "Gender model loaded\n",
      "Facial attibute analysis models loaded in  0.0  seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding embedding for pp.jpg: 100%|████████████████████████████████████████████████████| 12/12 [00:06<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings found for given data set in  6.013561964035034  seconds\n"
     ]
    }
   ],
   "source": [
    "DeepFace.stream(source = \"Simon Baker.MP4\", db_path = \"facial_db\", model_name = \"Facenet\", distance_metric = \"euclidean_l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459c090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  facial_db  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  11  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.6686251163482666  seconds\n",
      "           identity  VGG-Face_cosine\n",
      "0   facial_db/b.jpg         0.177054\n",
      "1   facial_db/a.jpg         0.194646\n",
      "2  facial_db/cc.jpg         0.321201\n",
      "3  facial_db/aa.jpg         0.330069\n",
      "Number of faces 1\n",
      "WARNING: Representations for images in  facial_db  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  11  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.909487247467041  seconds\n",
      "           identity  VGG-Face_cosine\n",
      "0   facial_db/b.jpg         0.177054\n",
      "1   facial_db/a.jpg         0.194646\n",
      "2  facial_db/cc.jpg         0.321201\n",
      "3  facial_db/aa.jpg         0.330069\n",
      "Number of faces 1\n",
      "12.156948566436768\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    " \n",
    "# Opens the Video file\n",
    "cap= cv2.VideoCapture('Simon Baker.mp4')\n",
    "i=0\n",
    "recog = 0\n",
    "start= time.time()\n",
    "\n",
    "while(cap.isOpened() and i <= int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    while(math.floor(time.time()) % 10 == 0):\n",
    "        \n",
    "        cv2.imwrite('kang.jpg',frame)\n",
    "        recognition = dfc.find(img_path = 'kang.jpg', db_path = 'facial_db', enforce_detection = False)\n",
    "        print(recognition)\n",
    "        if(recognition.shape[0] > 0):\n",
    "            recog += 1\n",
    "            cv2.imwrite('kang'+str(i)+'.jpg',frame)\n",
    "        \n",
    "        image = cv2.imread(\"a.jpg\")\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30))\n",
    "\n",
    "        print(\"Number of faces\", len(faces))\n",
    "        if(len(faces) > 1):\n",
    "            print(\"Multiple Faces Found.\")\n",
    "            break\n",
    "        \n",
    "        os.remove('kang.jpg')\n",
    "    recognition = np.nan\n",
    "    i+=1\n",
    "print(time.time() - start)\n",
    "\n",
    "if(recog == 0):\n",
    "    print(\"Candidate either had not attended the Test Properly. Or their might be some technical Issue\")\n",
    "    \n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fa202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# imagePath = \n",
    "\n",
    "# image = cv2.imread(\"a.jpg\")\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "# faces = faceCascade.detectMultiScale(\n",
    "#     gray,\n",
    "#     scaleFactor=1.3,\n",
    "#     minNeighbors=3,\n",
    "#     minSize=(30, 30)\n",
    "# )\n",
    "\n",
    "# print(\"There are \", len(faces), \" faces in the image\")\n",
    "# print(start-time.time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# print(\"[INFO] Found {0} Faces!\".format(len(faces)))\n",
    "\n",
    "# for (x, y, w, h) in faces:\n",
    "#     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# status = cv2.imwrite('faces_detected.jpg', image)\n",
    "# print(\"[INFO] Image faces_detected.jpg written to filesystem: \", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e97bd70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5727\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"Daniel2.mp4\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f505b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Needed Libraries\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Setting Up Time\n",
    "start = time.time()\n",
    " \n",
    "# Opens the Video file\n",
    "cap= cv2.VideoCapture('Daniel2.mp4')\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "i=50\n",
    "recog = 0\n",
    "start= time.time()\n",
    "\n",
    "img1 = \"pp.jpg\"\n",
    "img2 = \"\"\n",
    "\n",
    "\n",
    "while(cap.isOpened() and i <= length):\n",
    "    \n",
    "# Extracting Frames\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    while(i <= length):  \n",
    "        \n",
    "# Keep checking if the concerned candidate is in the video.\n",
    "        \n",
    "        cv2.imwrite('kang.jpg',frame)\n",
    "        recognition = dfc.find(img_path = 'kang.jpg', db_path = 'facial_db', enforce_detection = False)\n",
    "        \n",
    "        if(recognition.shape[0] > recognition['VGG-Face_cosine'][0] > 2):\n",
    "            print(recognition)\n",
    "        \n",
    "        \n",
    "        if(recognition.shape[0] == 0 or recognition['VGG-Face_cosine'][0] < 2):\n",
    "            recog += 1\n",
    "            img2 = 'kang'+str(i)+'.jpg'\n",
    "            cv2.imwrite('kang'+str(i)+'.jpg',frame)\n",
    "            \n",
    "            verification = dfc.verify(img1_path = img1, img2_path = img2, enforce_detection = False)\n",
    "            if(verification['verified']):\n",
    "                os.remove(img1)\n",
    "            \n",
    "            img1 = 'kang'+str(i)+'.jpg'\n",
    "            \n",
    "# Keep Checking the number of person's infront of the camera.\n",
    "\n",
    "        image = cv2.imread('kang.jpg')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "        faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30))\n",
    "\n",
    "        \n",
    "        print(\"Number of faces\", len(faces))\n",
    "        if(len(faces) > 1):\n",
    "            \n",
    "            print(\"Multiple Faces Found.\")\n",
    "            recog += 1\n",
    "            img2 = 'kang'+str(i)+'.jpg'\n",
    "            cv2.imwrite('kang'+str(i)+'.jpg',frame)\n",
    "            verification = dfc.verify(img1_path = img1, img2_path = img2, enforce_detection = False)\n",
    "            if(verification['verified']):\n",
    "                os.remove(img1)\n",
    "            \n",
    "            img1 = 'kang'+str(i)+'.jpg'\n",
    "            break\n",
    "        os.remove('kang.jpg')\n",
    "        i = i + 1000    \n",
    "    recognition = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "# This code will help you to check if the candidates behaviour was proper and Has the test gone smoothly.\n",
    "    \n",
    "if(recog > 3):\n",
    "    print(\"Candidate either had not attended the Test Properly. Or their might be some technical Issue\")\n",
    "    \n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e0382b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07603ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
